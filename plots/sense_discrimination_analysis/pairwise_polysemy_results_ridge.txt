model	semantic_variable	pairwise_accuracy	p-value
opt-1.3b_top_twelve	concreteness	0.83	0.0002
opt-1.3b_mid_four	concreteness	0.85	0.0006
opt-1.3b_top_four	concreteness	0.83	0.0006
gpt2-xl_mid_four	concreteness	0.82	0.0006
gpt2-xl_top_four	concreteness	0.79	0.0027
opt-1.3b_top_twelve	imageability	0.78	0.0006
opt-1.3b_mid_four	imageability	0.78	0.0011
opt-1.3b_top_four	imageability	0.78	0.0005
gpt2-xl_mid_four	imageability	0.8	0.0007
gpt2-xl_top_four	imageability	0.73	0.0018
opt-1.3b_top_twelve	familiarity	0.62	0.1056
opt-1.3b_mid_four	familiarity	0.67	0.0329
opt-1.3b_top_four	familiarity	0.62	0.0839
gpt2-xl_mid_four	familiarity	0.61	0.1334
gpt2-xl_top_four	familiarity	0.62	0.0839
opt-1.3b_top_twelve	hearing	0.54	0.3535
opt-1.3b_mid_four	hearing	0.55	0.3535
opt-1.3b_top_four	hearing	0.62	0.0839
gpt2-xl_mid_four	hearing	0.54	0.3693
gpt2-xl_top_four	hearing	0.51	0.4501
opt-1.3b_top_twelve	sight	0.76	0.0015
opt-1.3b_mid_four	sight	0.74	0.0038
opt-1.3b_top_four	sight	0.7	0.0028
gpt2-xl_mid_four	sight	0.76	0.0015
gpt2-xl_top_four	sight	0.76	0.0027
opt-1.3b_top_twelve	smell	0.48	0.8594
opt-1.3b_mid_four	smell	0.47	0.8777
opt-1.3b_top_four	smell	0.4	0.9998
gpt2-xl_mid_four	smell	0.46	0.8661
gpt2-xl_top_four	smell	0.44	0.978
opt-1.3b_top_twelve	taste	0.3	0.9998
opt-1.3b_mid_four	taste	0.29	0.9998
opt-1.3b_top_four	taste	0.3	0.9998
gpt2-xl_mid_four	taste	0.29	0.9998
gpt2-xl_top_four	taste	0.23	0.9998
opt-1.3b_top_twelve	touch	0.67	0.0336
opt-1.3b_mid_four	touch	0.69	0.0186
opt-1.3b_top_four	touch	0.64	0.0529
gpt2-xl_mid_four	touch	0.71	0.0081
gpt2-xl_top_four	touch	0.63	0.0839
opt-1.3b_top_twelve	average	0.622	0.0001
opt-1.3b_mid_four	average	0.63	0.0001
opt-1.3b_top_four	average	0.611	0.0001
gpt2-xl_mid_four	average	0.624	0.0001
gpt2-xl_top_four	average	0.589	0.0015

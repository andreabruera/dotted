model	semantic_variable	pairwise_accuracy	p-value
opt-1.3b_top_twelve	concreteness	0.83	0.0002
opt-1.3b_mid_four	concreteness	0.85	0.0005
opt-1.3b_top_four	concreteness	0.83	0.0005
gpt2-xl_mid_four	concreteness	0.82	0.0005
gpt2-xl_top_four	concreteness	0.79	0.0007
opt-1.3b_top_twelve	imageability	0.78	0.0005
opt-1.3b_mid_four	imageability	0.78	0.0009
opt-1.3b_top_four	imageability	0.78	0.0004
gpt2-xl_mid_four	imageability	0.8	0.0006
gpt2-xl_top_four	imageability	0.76	0.0006
opt-1.3b_top_twelve	familiarity	0.62	0.1056
opt-1.3b_mid_four	familiarity	0.67	0.0316
opt-1.3b_top_four	familiarity	0.62	0.0869
gpt2-xl_mid_four	familiarity	0.61	0.1334
gpt2-xl_top_four	familiarity	0.6	0.1056
opt-1.3b_top_twelve	hearing	0.54	0.3431
opt-1.3b_mid_four	hearing	0.55	0.3431
opt-1.3b_top_four	hearing	0.62	0.084
gpt2-xl_mid_four	hearing	0.54	0.3587
gpt2-xl_top_four	hearing	0.57	0.1834
opt-1.3b_top_twelve	sight	0.76	0.0013
opt-1.3b_mid_four	sight	0.74	0.0038
opt-1.3b_top_four	sight	0.7	0.0028
gpt2-xl_mid_four	sight	0.76	0.0013
gpt2-xl_top_four	sight	0.72	0.002
opt-1.3b_top_twelve	smell	0.48	0.8361
opt-1.3b_mid_four	smell	0.47	0.8552
opt-1.3b_top_four	smell	0.4	0.9991
gpt2-xl_mid_four	smell	0.46	0.8433
gpt2-xl_top_four	smell	0.48	0.6856
opt-1.3b_top_twelve	taste	0.3	0.9991
opt-1.3b_mid_four	taste	0.29	0.9991
opt-1.3b_top_four	taste	0.3	0.9991
gpt2-xl_mid_four	taste	0.29	0.9991
gpt2-xl_top_four	taste	0.34	0.9991
opt-1.3b_top_twelve	touch	0.67	0.0323
opt-1.3b_mid_four	touch	0.69	0.0186
opt-1.3b_top_four	touch	0.64	0.0509
gpt2-xl_mid_four	touch	0.71	0.0081
gpt2-xl_top_four	touch	0.67	0.0316
opt-1.3b_top_twelve	average	0.622	0.0
opt-1.3b_mid_four	average	0.63	0.0
opt-1.3b_top_four	average	0.611	0.0001
gpt2-xl_mid_four	average	0.624	0.0
gpt2-xl_top_four	average	0.616	0.0
